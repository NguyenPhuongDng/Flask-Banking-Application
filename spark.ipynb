{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SQLite with PySpark\") \\\n",
    "    .config(\"spark.jars\", \"C:\\\\Users\\\\dongh\\\\Documents\\\\GitHub\\\\Flask-Banking-Application\\\\instance\\\\sqlite-jdbc-3.43.0.0.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn tới file SQLite\n",
    "db_path = \"instance/bank_app.db\"\n",
    "table_name = \"Application\"\n",
    "\n",
    "def read_sqlite_data(db_path, table_name):\n",
    "# Đọc dữ liệu từ SQLite\n",
    "    df = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", f\"jdbc:sqlite:{db_path}\") \\\n",
    "        .option(\"dbtable\", table_name) \\\n",
    "        .option(\"driver\", \"org.sqlite.JDBC\") \\\n",
    "        .load()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+------+--------+-------+------+--------+----------+\n",
      "| id|         name|age|employ|creddebt|debtinc|income| othdebt|    result|\n",
      "+---+-------------+---+------+--------+-------+------+--------+----------+\n",
      "|  1|        Đônng| 13|   4.0|     1.0|    1.0|   1.0|5.008608|No Default|\n",
      "|  2|            1| 13|   4.0|     1.0|    1.0|   1.0|5.008608|No Default|\n",
      "|  3|        Dongg| 19|   4.0|     1.0|    1.0|   1.0|5.008608|No Default|\n",
      "|  4|Đônng Nguuyễn| 13|   1.0|     1.0|    1.0|  14.0|    14.0|No Default|\n",
      "|  5|         Dông| 10|   1.0|     1.0|    1.0|  14.0|    14.0|No Default|\n",
      "|  6|         Dông| 10|   1.0|     1.0|    1.0|  14.0|    14.0|No Default|\n",
      "|  7|        Đônng| 41|  17.0|   11.36|    9.3| 176.0|     5.0|No Default|\n",
      "|  8|        Đônng| 41|  17.0|  11.359|    9.3| 176.0|5.008608|No Default|\n",
      "|  9|        Đônng| 41|   1.0|     2.0|    9.3| 176.0|5.008608|No Default|\n",
      "| 10|        Đônng| 41|   1.0|     2.0|    9.3| 176.0|5.008608|No Default|\n",
      "| 11|        Đônng| 41|   1.0|     2.0|    9.3| 176.0|5.008608|No Default|\n",
      "| 12|        Đônng| 41|   1.0|     2.0| 1000.0| 176.0|   100.0|   Default|\n",
      "| 13|        Đônng| 41|   1.0|     2.0| 1000.0| 176.0|   100.0|   Default|\n",
      "| 14|        Đônng| 41|   1.0|     2.0| 1000.0| 176.0|   100.0|   Default|\n",
      "| 15|        Đônng| 30|   1.0|     2.0| 1000.0| 176.0|   100.0|   Default|\n",
      "| 16|        Đônng|  9|   1.0|     2.0| 1000.0| 176.0|   100.0|   Default|\n",
      "+---+-------------+---+------+--------+-------+------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "application_df = read_sqlite_data(db_path, table_name)\n",
    "application_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n",
      "|    result|count|percentage|\n",
      "+----------+-----+----------+\n",
      "|   Default|    5|     31.25|\n",
      "|No Default|   11|     68.75|\n",
      "+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "application_df.createOrReplaceTempView(\"Application\")\n",
    "default_rate = spark.sql(\"\"\"\n",
    "    SELECT result, COUNT(*) AS count, \n",
    "           ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) AS percentage\n",
    "    FROM Application\n",
    "    GROUP BY result\n",
    "\"\"\")\n",
    "default_rate.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|age_group|count|\n",
      "+---------+-----+\n",
      "|     0-20|    7|\n",
      "|    21-40|    1|\n",
      "|    41-60|    8|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "age_group = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN age <= 20 THEN '0-20'\n",
    "            WHEN age <= 40 THEN '21-40'\n",
    "            WHEN age <= 60 THEN '41-60'\n",
    "            WHEN age <= 80 THEN '61-80'\n",
    "            ELSE '81+' \n",
    "        END AS age_group,\n",
    "        COUNT(*) AS count\n",
    "    FROM Application\n",
    "    GROUP BY age_group\n",
    "    ORDER BY age_group\n",
    "\"\"\")\n",
    "age_group.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|total|\n",
      "+-----+\n",
      "|   16|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_applications = spark.sql(\"SELECT COUNT(*) AS total FROM Application\")\n",
    "total_applications.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_with_count_in_buckets(application_df):\n",
    "    \n",
    "    # Đăng ký DataFrame như một view tạm thời để truy vấn bằng SQL\n",
    "    application_df.createOrReplaceTempView(\"Application\")\n",
    "    \n",
    "    # Truy vấn SQL với phân chia các khoảng income và debtinc\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN income <= 20 THEN '0-20'\n",
    "            WHEN income <= 40 THEN '21-40'\n",
    "            WHEN income <= 60 THEN '41-60'\n",
    "            WHEN income <= 80 THEN '61-80'\n",
    "            ELSE '81+' \n",
    "        END AS income_group,\n",
    "        COUNT(*) AS count\n",
    "    FROM Application\n",
    "    GROUP BY income_group\n",
    "    ORDER BY income_group\n",
    "    \"\"\"\n",
    "    \n",
    "    # Thực thi câu truy vấn SQL\n",
    "    result_df = spark.sql(query)\n",
    "    \n",
    "    # Hiển thị kết quả\n",
    "    result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|income_group|count|\n",
      "+------------+-----+\n",
      "|        0-20|    6|\n",
      "|         81+|   10|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = query_with_count_in_buckets(application_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
